{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __[:+:] -- DragonVision -- [:+:]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [+] Libraries that are commented out are only for ROS\n",
    "#import rospy\n",
    "#from std_msgs.msg import Float64\n",
    "#from sensor_msgs.msg import Image\n",
    "#from cv_bridge import CvBridge, CvBridgeError\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "#[+------:\n",
    "import sys\n",
    "\n",
    "bgrRed= (0, 0, 255)\n",
    "bgrBlue= (255, 0, 0)\n",
    "bgrCyan= (200, 200, 50)\n",
    "bgrOrange= (100, 100, 255)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Gate (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "#[+]- Each iteration of this loop processes a frame that is captured by the camera by applying a series of filters. Each filter is in intermediate step, the final image is the one which we annotate and extract information from. \n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # color bounds of color to be filtered out [+] correction: colors to be NOT filtered out\n",
    "    # lower_color_bounds = np.array([0, 200, 0])\n",
    "    # upper_color_bounds = np.array([255, 255, 255])\n",
    "    lower_color_bounds = np.array([0, 100, 20])\n",
    "    upper_color_bounds = np.array([30, 255, 255])\n",
    "\n",
    "\n",
    "    # [+]- Filter 1: threshold shows in black the pixels being filtered out [+: show only the colors that are between the two bounds)\n",
    "    threshold = cv2.inRange(hsv, lower_color_bounds, upper_color_bounds)\n",
    "\n",
    "    #[+]- Filter 2:  erode to remove noise\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    erode = cv2.erode(threshold, kernel)\n",
    "\n",
    "    # get the contours, Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object\n",
    "    contours = cv2.findContours(erode, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "    # create bounding boxes, creates an array of contour areas so that we can know which is th ebiggest\n",
    "    contour_areas = [cv2.contourArea(x) for x in contours]  \n",
    "    \n",
    "    # get the areas of each contour, returns a list of indeces for contour areas array\n",
    "    contour_indexes = np.argsort(contour_areas)  \n",
    "    \n",
    "    # sort the indexes of the largest areas\n",
    "    for i in contour_indexes[-2:]:  # only look at the two largest contours\n",
    "        (x,y,w,h) = cv2.boundingRect(contours[i])  # get the location/dimensions of a bounding box for the contour: x,y=coordinates, w,h=dims\n",
    "        cv2.rectangle(final, pt1=(x,y), pt2=(x+w,y+h), color=(255,0,0), thickness=5)  # draw the bounding box on the image\n",
    "\n",
    "        # for visibility, we will place a background fill on the contour label\n",
    "        text = \"gatepost\"\n",
    "        text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)\n",
    "        text_w, text_h = text_size\n",
    "        cv2.rectangle(final, pt1=(x, y), pt2=(x + text_w, y - 2*text_h), color=(255, 0, 0), thickness=-1)\n",
    "        cv2.putText(final, \"gatepost\", org=(x, y-5), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 255, 255), thickness=1)\n",
    "\n",
    "    # [+]- Show each filter that is applied to the frame. Each filter is shown in a separate window\n",
    "    # cv2.imshow('1 Gate: original frame',frame)\n",
    "    cv2.imshow('2 Gate: threshold', threshold)\n",
    "    cv2.imshow(\"3 Gate: eroded\", erode)\n",
    "    cv2.imshow(\"4 Gate: final\", final)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Buoy (2022)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27872/2551703912.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# video_capture = cv2.VideoCapture(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# video_capture = cv2.VideoCapture(2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "# # color bounds of color to be [NOT] filtered out, by default it filters out light colors so that it can identif \n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 45])\n",
    "\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "lower_value_bounds2 = np.array([0, 0, 0])\n",
    "upper_value_bounds2 = np.array([255, 255, 80])\n",
    "clk= 0\n",
    "clkRate= 9\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "dilateKernel = np.ones((5, 5), np.uint8)\n",
    "erodeKernel = np.ones((10, 10), np.uint8)\n",
    "erodeKernel2= np.ones((6, 6), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "\n",
    "\n",
    "while(True):\n",
    "    # Capture the frames\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # change from bgr values to hsv values\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\n",
    "    # threshold shows in black the pixels being filtered out\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "\n",
    "    #  [+:] -- Use this to find the ideal value range, which changes depending on the lighting ----------//\n",
    "    tick= clk//clkRate\n",
    "    # img_threshold = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, tick]))\n",
    "    # cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 150, 0), thickness=2)\n",
    "    # clk+= 1\n",
    "    # if clk>clkLim: clk=0\n",
    "    #-----------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # dilate to combine contours\n",
    "    img_dilate = cv2.dilate(img_threshold, dilateKernel, iterations=3)\n",
    "\n",
    "    # erode to remove noise\n",
    "    img_erode = cv2.erode(img_dilate, erodeKernel, iterations=2)\n",
    "\n",
    "    # blur to smooth edges so circle detection is easier\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    # detect circles\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    # if a circle is identified\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        # draw the circles\n",
    "        circle_radii = [x[2] for x in circles[0]]  # get the radii of each contour\n",
    "        circle_indexes = np.argsort(circle_radii)  # sort by largest radius\n",
    "        for i in circle_indexes[-2:]:  # only contour at the largest circles\n",
    "            circle = circles[0][i]  # get the largest circle\n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=(100, 0, 255), thickness=2)  # draw the circle on the image\n",
    "            # make the text centered\n",
    "            # text = \"police buoy\"\n",
    "            text = \" --  -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+8), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=(100, 0, 255), thickness=2)\n",
    "\n",
    "\n",
    "    #[:+:]===============================================================================================================================================[:+:]\n",
    "    clkRate= 1\n",
    "    #[+]-------- ----------------------------------------------------------------------------//\n",
    "    img_threshold2 = cv2.inRange(img_hsv, np.array([0, 0, 0]), np.array([255, 255, 80]))\n",
    "    cv2.putText(img_final, (\"[:+:] CLK: \"+ str(tick)), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(100, 255, 100), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #----------------------------------------------------------------------------------------//\n",
    "\n",
    "    img_erode2 = cv2.erode(img_threshold2, erodeKernel2, iterations=1)\n",
    "\n",
    "    dilateKernel2 = np.ones((5, 5), np.uint8)\n",
    "\n",
    "    img_dilate2 = cv2.dilate(img_erode2, dilateKernel2, iterations=3)\n",
    "\n",
    "    img_blur2 = cv2.blur(img_erode2, ksize=blurnel)\n",
    "\n",
    "    circles2 = cv2.HoughCircles(img_blur2, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=30,  # edge detection parameter\n",
    "                  param2=30,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "#[+:] --- Circle Array # 2 -----------------------------------------\n",
    "    if (type(circles2)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles2[0]]  \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]:  \n",
    "            circle = circles2[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2])+25, color=(200, 150, 0), thickness=2) \n",
    "            text = \"[:+:]\"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, 1, 1)  \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+text_h), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=2, color=(200, 150, 0), thickness=2)\n",
    "#[:\\:]===============================================================================================================================================[:\\:]\n",
    "\n",
    "\n",
    "\n",
    "    # [+] show frames\n",
    "    # cv2.imshow('1 original frame', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv', img_hsv)\n",
    "    # cv2.imshow('3 Buoy: threshold', img_threshold)\n",
    "    # cv2.imshow(\"4 Buoy: dilated\", img_dilate)\n",
    "    # cv2.imshow(\"5 Buoy: eroded\", img_erode)\n",
    "    # cv2.imshow(\"6 Buoy: blur\", img_blur)\n",
    "    # cv2.imshow(\"7 Buoy: final\", img_final)\n",
    "\n",
    "    #[+: ------------------------------------------------- ::\n",
    "    # cv2.imshow('1 original frame2', img_frame)\n",
    "    # cv2.imshow('2 Buoy: hsv2', img_hsv)\n",
    "    cv2.imshow('3 Buoy: threshold2', img_threshold2)\n",
    "    cv2.imshow(\"4 Buoy: dilated2\", img_dilate2)\n",
    "    cv2.imshow(\"5 Buoy: eroded2\", img_erode2)\n",
    "    cv2.imshow(\"6 Buoy: blur2\", img_blur2)\n",
    "    #::-----------------------------------------------------:+]\n",
    "    cv2.imshow(\"7 Buoy: final2\", img_final)\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 0])\n",
    "upper_value_bounds = np.array([255, 255, 75])\n",
    "\n",
    "houghParam1=40\n",
    "houghParam2=45\n",
    "# houghParam1=15\n",
    "# houghParam2=30\n",
    "\n",
    "#[+:]-- -------------------------------------------------//\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "#-------------------------------------------------------//\n",
    "\n",
    "\n",
    "kernel_sqr = np.ones((1,1), np.uint8)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "blurnel = (2, 2)\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, \"[:+:] CLK: \"+ str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.7, color=(200, 0, 255), thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "    # #[::+::]======================Debug================|+|+|+|\n",
    "    # clkRate= 1\n",
    "    # upper_value_bounds = np.array([255, 255, 75])\n",
    "    # # [\\\\+\\\\]===========================================|-|-|-|\n",
    "\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    img_dilate = cv2.dilate(img_threshold, kernel_1x3, iterations=4)\n",
    "    img_erode = cv2.erode(img_dilate, kernel_1x3, iterations=4)\n",
    "    img_blur = cv2.blur(img_erode, ksize= blurnel)\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  # accumulator threshold, or how circley the circles need to be to be recognized (higher=more circlely)\n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]+20), color=bgrOrange, thickness=2)  \n",
    "            text = \" -- -- \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1)  # get the text size\n",
    "            text_w, text_h = text_size  # get the text width/height\n",
    "            cv2.putText(img_final, text, org=(int(circle[0])-text_w, int(circle[1])+(text_h//2)+7), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=bgrOrange, thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('3 Circle_1: threshold', img_threshold)\n",
    "    cv2.imshow(\"4 Circle1_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_1: eroded\", img_erode)\n",
    "    cv2.imshow(\"6 Circle_1: blur\", img_blur)\n",
    "    cv2.imshow(\"7 Circle_1: final\", img_final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[::] Circle Detection 2__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "# [+]- Access the camera, the int parameter determines which camera you are using, may have to change in depending on what computer you run on\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "# video_capture = cv2.VideoCapture(1)\n",
    "# video_capture = cv2.VideoCapture(2)\n",
    "\n",
    "lower_value_bounds = np.array([0, 0, 150])\n",
    "# lower_value_bounds = np.array([0, 0, 165])\n",
    "# lower_value_bounds = np.array([0, 0, 180])\n",
    "upper_value_bounds = np.array([255, 255, 255])\n",
    "\n",
    "# houghParam1=40\n",
    "# houghParam2=45\n",
    "houghParam1=15\n",
    "houghParam2=30\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "\n",
    "\n",
    "kernel_sqr2 = np.ones((2,2), np.uint8)\n",
    "kernel_sqr3 = np.ones((3,3), np.uint8)\n",
    "kernel_sqr4 = np.ones((4,4), np.uint8)\n",
    "kernel_sqr5 = np.ones((5,5), np.uint8)\n",
    "kernel_sqr6 = np.ones((6,6), np.uint8)\n",
    "kernel_sqr7 = np.ones((7,7), np.uint8)\n",
    "kernel_sqr8 = np.ones((8,8), np.uint8)\n",
    "kernel_sqr9 = np.ones((9,9), np.uint8)\n",
    "kernel_sqr10 = np.ones((10,10), np.uint8)\n",
    "kernel_sqr11 = np.ones((11,11), np.uint8)\n",
    "kernel_sqr12 = np.ones((12,12), np.uint8)\n",
    "kernel_sqr13 = np.ones((13,13), np.uint8)\n",
    "kernel_sqr13 = np.ones((14,14), np.uint8)\n",
    "blurnel = (5, 5)\n",
    "kernel_3x1= np.ones((3,1), np.uint8)\n",
    "kernel_1x3= np.ones((1,3), np.uint8)\n",
    "kernel_2x1= np.ones((2,1), np.uint8)\n",
    "kernel_sqr= np.empty((0,), dtype= np.ndarray)\n",
    "erodeKernel= kernel_sqr8\n",
    "morphKernel= np.ones((2,2), np.uint8)\n",
    "\n",
    "while(True):\n",
    "    ret, img_frame = video_capture.read()\n",
    "    img_final = img_frame\n",
    "\n",
    "    # [+:]--- Use this to find the ideal value range, which changes depending on the lighting ---------------------//\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(img_final, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    #--------------------------------------------------------------------------------------------------------------//\n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\n",
    "    #-- circl 3 starter ----\n",
    "    # clkRate= 3\n",
    "    # morphKernel= cv2.getStructuringElement(cv2.MORPH_CROSS, (2,2))  \n",
    "    # morphKernel2= cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "    # blurnel2= (3, 3)\n",
    "    # morphDilate_i= 1\n",
    "    # img_blur = cv2.blur(img_morphDilate, ksize= blurnel2)\n",
    "    # img_morphDilate = cv2.dilate(img_morph,morphKernel2, iterations=morphDilate_i)\n",
    "    # morphKernel= np.ones((2,2), np.uint8)\n",
    "    # img_morph= cv2.morphologyEx(img_threshold, cv2.MORPH_GRADIENT, morphKernel)\n",
    "\n",
    "    # cv2.imshow('4.5 Circle_2: morph', img_morph)\n",
    "    # cv2.imshow('4.5 Circle_2: tmp morph->dil', img_morphDilate)\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|\n",
    "\n",
    "    img_hsv = cv2.cvtColor(img_frame, cv2.COLOR_BGR2HSV)\n",
    "    img_threshold = cv2.inRange(img_hsv, lower_value_bounds, upper_value_bounds)\n",
    "    #[+:]-- erodeKernel= np.ones((7:14,7:14), np.uint8)\n",
    "    img_erode = cv2.erode(img_threshold, erodeKernel, iterations=1)\n",
    "    img_dilate = cv2.dilate(img_erode, kernel_sqr6, iterations=1)\n",
    "    img_blur = cv2.blur(img_dilate, ksize= blurnel)\n",
    "    \n",
    "\n",
    "\n",
    "    circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                  param1=houghParam1,  # edge detection parameter\n",
    "                  param2=houghParam2,  \n",
    "                  minRadius=0,\n",
    "                  maxRadius=100)\n",
    "\n",
    "    if (type(circles)) is np.ndarray:\n",
    "        circle_radii = [x[2] for x in circles[0]] \n",
    "        circle_indexes = np.argsort(circle_radii)  \n",
    "        for i in circle_indexes[-2:]: \n",
    "            circle = circles[0][i] \n",
    "            cv2.circle(img_final, center=(int(circle[0]), int(circle[1])), radius=int(circle[2]), color=bgrCyan, thickness=2)  \n",
    "            text = \" + \"\n",
    "            text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, 1, 1) \n",
    "            text_w, text_h = text_size  \n",
    "            cv2.putText(img_final, text, org=(int(circle[0]-text_w), int(circle[1])+(text_h//2)+7), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=2, color=bgrOrange, thickness=2)\n",
    "            \n",
    "    # cv2.imshow('2 Circle_1: hsv', img_hsv)\n",
    "    cv2.imshow('1 Circle_2: threshold', img_threshold)\n",
    "    cv2.imshow(\"2 Circle_2: eroded\", img_erode)\n",
    "    cv2.imshow(\"4 Circle_2_: dilated\", img_dilate)\n",
    "    cv2.imshow(\"5 Circle_2: blur\", img_blur)\n",
    "    cv2.imshow(\"6 Circle_2: final\", img_final)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Circle Detection 3__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] OCR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_yaw = 0\n",
    "cv_image = 0\n",
    "YAW_VARIANCE = .017\n",
    "\n",
    "camNum= 0\n",
    "video_capture = cv2.VideoCapture(camNum)\n",
    "\n",
    "clk= 0\n",
    "clkRate= 1\n",
    "clkLim= clkRate*255\n",
    "\n",
    "grayUpp= 255\n",
    "grayLow= 150\n",
    "threshUpp= 255\n",
    "threshLow= 150\n",
    "hsvLow = np.array([0, 0, 218])\n",
    "hsvUpp = np.array([157, 54, 255])\n",
    "\n",
    "dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))  \n",
    "dilate_i= 9\n",
    "\n",
    "minW= 35\n",
    "minH= 35\n",
    "maxW= 300\n",
    "maxH= 300\n",
    "\n",
    "while(True):\n",
    "    ret, frame = video_capture.read()\n",
    "    final = frame\n",
    "\n",
    "    ##[+:]=== Use this to find the ideal value range, which changes depending on the lighting ===============================\\\\\n",
    "    tick= clk//clkRate + 1\n",
    "    cv2.putText(frame, str(tick), org=(10, 20), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=.5, color= bgrOrange, thickness=2)\n",
    "    clk+= 1\n",
    "    if clk>clkLim: clk=0\n",
    "    ##=======================================================================================================================//\n",
    "\n",
    "\n",
    "    #--option 1: use grayscale-----\n",
    "    img2gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, grayMask = cv2.threshold(img2gray, grayLow, grayUpp, cv2.THRESH_BINARY)\n",
    "    imgFinal_gray = cv2.bitwise_and(img2gray, img2gray, mask=grayMask)\n",
    "\n",
    "    #---Option 2: use hsv-----------\n",
    "    img2hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    hsvMask = cv2.inRange(img2hsv, hsvLow, hsvUpp)\n",
    "    \n",
    "    # for black text , cv.THRESH_BINARY_INV\n",
    "    ret, new_img = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY)  \n",
    "    ret, new_img_inv = cv2.threshold(imgFinal_gray, threshLow, threshUpp, cv2.THRESH_BINARY_INV)  \n",
    "\n",
    "#[::+::]==========|============Debug===========|===========================|+|+|+|\\\\\n",
    "    # clkRate= 21\n",
    "    # erodeKernel= np.ones((tick,tick), np.uint8)\n",
    "    # threshLow= 255-tick\n",
    "    # dilateKernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (tick,tick))  \n",
    "    # dilate_i= tick\n",
    "#[\\\\+\\\\]==========|============================|===========================|-|-|-|//\n",
    "\n",
    "    # dilate , more the iteration more the dilation\n",
    "    dilated = cv2.dilate(new_img_inv, dilateKernel, iterations= dilate_i)  \n",
    "\n",
    "\n",
    "    # for cv2.x.x: \n",
    "    # _, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)  # findContours returns 3 variables for getting contours\n",
    "\n",
    "    # for cv3.x.x  comment above line and uncomment line below:\n",
    "    #image, contours, hierarchy = cv2.findContours(dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # [::]-- Selection: \n",
    "    contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    for contour in contours:\n",
    "        [x, y, w, h] = cv2.boundingRect(contour)\n",
    "\n",
    "        # if w < minW and h < minH:\n",
    "        #     continue\n",
    "        # if w > maxW and h > maxH:\n",
    "        #     continue\n",
    "\n",
    "        if w<maxW and h<maxH and w>minW and h>minH:\n",
    "            # draw rectangle around contour on original image\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 255), 2)\n",
    "            cv2.putText(frame, '[' + str(w)+'x'+str(h)+']', org=(x+w//2, y+h//2), \n",
    "                        fontFace=cv2.FONT_HERSHEY_DUPLEX, \n",
    "                        fontScale=.5, color= bgrCyan, \n",
    "                        thickness=2)\n",
    "\n",
    " \n",
    "    #cv2.imshow('0 original frame',frame)\n",
    "    cv2.imshow('1 threshold', imgFinal_gray)\n",
    "    cv2.imshow(\"1 grayMask\", grayMask)\n",
    "    # cv2.imshow(\"2  hsvMask\", hsvMask)\n",
    "    # cv2.imshow(\"3 White Text\", new_img)\n",
    "    cv2.imshow(\"4 Black Text\", new_img_inv)\n",
    "    cv2.imshow(\"5 dilated\", dilated)\n",
    "    cv2.imshow(\"6 final\", final)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  __[:+:] Tasks__\n",
    "- [x] Gate Task Circle Detection 1\n",
    "- [x] Gate Task Circle Detection 2\n",
    "- [ ] OCR\n",
    "- [ ] Morphological Gradient; gradient = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)\n",
    "- [ ] Trimmed Mean\n",
    "- [ ] Box Detection\n",
    "- [ ] Ensemble of Algorithms\n",
    "    - [ ] Helper Functions\n",
    "    - [ ] Polling System\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10065f837bc8873f5387f5268b450066d881a20043fa6c000aa3f801fbe31849"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
